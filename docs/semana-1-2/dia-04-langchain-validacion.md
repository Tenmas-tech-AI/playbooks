---
sidebar_position: 5
title: "D√≠a 4: LangChain + Validaci√≥n del Stack"
---

# D√≠a 4: LangChain + Validaci√≥n del Stack

**Duraci√≥n:** ~4 horas | **Estado:** ‚úÖ Completo

‚¨ÖÔ∏è **Anterior:** [D√≠a 3 ‚Äî n8n + Playwright](./dia-03-n8n-playwright)

## Objetivo del d√≠a

Al terminar este d√≠a debes tener:
- LangChain instalado y corriendo con Claude (Anthropic) o GPT (OpenAI)
- Un agent funcional de prueba que resuelve una tarea real
- LangSmith configurado para observabilidad de las llamadas al LLM
- Todo el stack de los D√≠as 1‚Äì4 validado y comunic√°ndose sin errores

---

## Parte 1: LangChain

**Tiempo estimado:** 2.5 horas

### Prerequisitos

- Node.js 18+ o Python 3.9+
- `ANTHROPIC_API_KEY` o `OPENAI_API_KEY` disponible
- Un proyecto con `package.json` o `pyproject.toml` existente

:::tip LLM recomendado para Tenm√°s
Usa **Anthropic Claude** si ya tienes cr√©ditos del D√≠a 2 (PromptLayer setup). Usa **OpenAI** si el equipo ya tiene cuenta activa. LangChain soporta ambos con la misma API.
:::

### Instalaci√≥n

**Node.js / TypeScript:**

```bash
npm install langchain @langchain/anthropic @langchain/openai
# o solo el que vas a usar:
npm install langchain @langchain/anthropic
npm install langchain @langchain/openai
```

**Python:**

```bash
pip install langchain langchain-anthropic langchain-openai
```

### Variables de entorno

```bash
# .env
ANTHROPIC_API_KEY=sk-ant-xxxx
OPENAI_API_KEY=sk-xxxx          # solo si usas OpenAI

# LangSmith ‚Äî observabilidad (ver Parte 2)
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=lsv2_pt_xxxx
LANGCHAIN_PROJECT=nombre-del-proyecto
```

:::caution
Nunca subas el `.env` al repositorio. Aseg√∫rate de que est√° en el `.gitignore`:
```
.env
```
:::

### Configuraci√≥n m√≠nima para el stack de Tenm√°s

**TypeScript:**

```typescript
// src/ai/client.ts
import { ChatAnthropic } from "@langchain/anthropic";
import { ChatOpenAI } from "@langchain/openai";

// Elige uno seg√∫n el LLM que uses en Tenm√°s
export const llm = new ChatAnthropic({
  model: "claude-haiku-4-5-20251001",
  temperature: 0,
  apiKey: process.env.ANTHROPIC_API_KEY,
});

// export const llm = new ChatOpenAI({
//   model: "gpt-4o-mini",
//   temperature: 0,
//   apiKey: process.env.OPENAI_API_KEY,
// });
```

**Python:**

```python
# src/ai/client.py
from langchain_anthropic import ChatAnthropic
from langchain_openai import ChatOpenAI
import os

llm = ChatAnthropic(
    model="claude-haiku-4-5-20251001",
    temperature=0,
    api_key=os.environ["ANTHROPIC_API_KEY"],
)

# llm = ChatOpenAI(
#     model="gpt-4o-mini",
#     temperature=0,
#     api_key=os.environ["OPENAI_API_KEY"],
# )
```

### Agent de prueba: PR Reviewer

Este agent recibe el diff de un PR y genera un resumen t√©cnico. Es el caso de uso m√°s relevante para el stack de Tenm√°s ‚Äî conecta directamente con el flujo de GitHub del D√≠a 3.

**TypeScript:**

```typescript
// src/ai/pr-reviewer.ts
import { ChatPromptTemplate } from "@langchain/core/prompts";
import { StringOutputParser } from "@langchain/core/output_parsers";
import { llm } from "./client";

const prompt = ChatPromptTemplate.fromMessages([
  [
    "system",
    `Eres un code reviewer t√©cnico. Analiza el diff de PR y responde en espa√±ol con:
1. Resumen de cambios (2-3 l√≠neas)
2. Riesgos detectados (si los hay)
3. Sugerencia de mejora m√°s importante (solo una)

S√© directo y conciso.`,
  ],
  ["human", "Diff del PR:\n\n{diff}"],
]);

const chain = prompt.pipe(llm).pipe(new StringOutputParser());

export async function reviewPR(diff: string): Promise<string> {
  return chain.invoke({ diff });
}

// Prueba local
const testDiff = `
+++ b/src/auth/login.ts
@@ -10,6 +10,12 @@ export async function login(email: string, password: string) {
+  const user = await db.query('SELECT * FROM users WHERE email = ' + email);
+  if (!user) throw new Error('User not found');
+  return generateToken(user);
`;

reviewPR(testDiff).then(console.log).catch(console.error);
```

```bash
# Ejecutar
npx ts-node src/ai/pr-reviewer.ts
# o con tsx:
npx tsx src/ai/pr-reviewer.ts
```

**Python:**

```python
# src/ai/pr_reviewer.py
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from src.ai.client import llm

prompt = ChatPromptTemplate.from_messages([
    ("system", """Eres un code reviewer t√©cnico. Analiza el diff de PR y responde en espa√±ol con:
1. Resumen de cambios (2-3 l√≠neas)
2. Riesgos detectados (si los hay)
3. Sugerencia de mejora m√°s importante (solo una)

S√© directo y conciso."""),
    ("human", "Diff del PR:\n\n{diff}"),
])

chain = prompt | llm | StrOutputParser()

def review_pr(diff: str) -> str:
    return chain.invoke({"diff": diff})

if __name__ == "__main__":
    test_diff = """
+++ b/src/auth/login.py
@@ -10,6 +10,4 @@ def login(email, password):
+    user = db.execute(f"SELECT * FROM users WHERE email = {email}")
+    if not user: raise Exception("User not found")
+    return generate_token(user)
    """
    print(review_pr(test_diff))
```

```bash
python src/ai/pr_reviewer.py
```

### Salida esperada del agent

```
1. **Resumen:** Se agrega funci√≥n de login que consulta usuario por email y genera token de sesi√≥n.

2. **Riesgos:** SQL injection cr√≠tico ‚Äî la query concatena el input directamente sin sanitizar.
   Cualquier valor en `email` se ejecuta como SQL.

3. **Sugerencia:** Usar prepared statements o un ORM:
   `db.query('SELECT * FROM users WHERE email = $1', [email])`
```

### Verificaci√≥n

```bash
# TypeScript
npx tsx src/ai/pr-reviewer.ts

# Python
python src/ai/pr_reviewer.py
```

La respuesta debe aparecer en consola en menos de 10 segundos. Si tarda m√°s de 30s, hay un problema de red o la API key es inv√°lida.

### Qu√© NO configurar todav√≠a

- **Pinecone / vector stores** ‚Äî se integran en la fase de RAG (no est√° en el scope de semanas 1-2)
- **Agents con tools complejas** ‚Äî el agent de prueba es intencionalmente simple
- **Memory persistente** ‚Äî requiere base de datos, se dise√±a seg√∫n el proyecto espec√≠fico
- **Streaming de respuestas** ‚Äî √∫til para UX pero no necesario en esta fase

### Troubleshooting

**Error: `AuthenticationError: Invalid API key`**

La API key est√° mal configurada. Verifica:

```bash
# Verifica que la variable existe
echo $ANTHROPIC_API_KEY
# o
node -e "console.log(process.env.ANTHROPIC_API_KEY)"
```

Aseg√∫rate de que el `.env` se carga antes de importar el cliente. Usa `dotenv` al inicio del archivo de entrada:

```typescript
import "dotenv/config"; // debe ser el primer import
```

**Error: `Cannot find module '@langchain/anthropic'`**

El paquete no est√° instalado o hay un conflicto de versiones:

```bash
npm install @langchain/anthropic@latest
# Si persiste, limpia cach√©:
rm -rf node_modules package-lock.json && npm install
```

**Error: `RateLimitError` o respuestas muy lentas**

La cuenta tiene rate limits bajos (cuentas nuevas de Anthropic tienen l√≠mites estrictos). Soluciones:

```typescript
// Agregar retry autom√°tico
const llm = new ChatAnthropic({
  model: "claude-haiku-4-5-20251001",
  maxRetries: 3,
  temperature: 0,
});
```

O cambia a un modelo m√°s barato/r√°pido temporalmente: `claude-haiku-4-5-20251001` es el m√°s r√°pido de Claude.

---

## Parte 2: LangSmith ‚Äî Observabilidad de LangChain

**Tiempo estimado:** 30 minutos

LangSmith es el dashboard oficial de LangChain. Registra autom√°ticamente cada ejecuci√≥n del pipeline: qu√© prompt se mand√≥, qu√© retorn√≥ el LLM, cu√°nto tard√≥ cada paso, cu√°ntos tokens se usaron.

### LangSmith vs PromptLayer

Ambas herramientas son complementarias ‚Äî se usan en momentos distintos del ciclo de desarrollo:

| | **LangSmith** | **PromptLayer** |
|---|---|---|
| **Enfoque** | Debuggear el pipeline completo | Gestionar y versionar prompts |
| **Qu√© muestra** | Cada paso del chain (prompt ‚Üí LLM ‚Üí parser) | La llamada al LLM y la respuesta |
| **Mejor para** | Entender por qu√© fall√≥ un agent | Ver qu√© prompt genera mejores respuestas |
| **Versionado de prompts** | No | S√≠ ‚Äî A/B testing de prompts |
| **Configuraci√≥n** | Variables de entorno, nada en el c√≥digo | Wrapper en el cliente |

**Regla pr√°ctica:**
- Usa **LangSmith** cuando est√°s **desarrollando** y necesitas ver qu√© pasa dentro del pipeline
- Usa **PromptLayer** cuando est√°s **iterando sobre el prompt** y quieres comparar versiones en producci√≥n

### Setup de LangSmith

**1. Crea la cuenta:**

Ve a [smith.langchain.com](https://smith.langchain.com) y crea una cuenta gratuita (no requiere tarjeta de cr√©dito).

**2. Obt√©n la API key:**

Settings ‚Üí API Keys ‚Üí **Create API Key**

La key empieza con `lsv2_pt_...`

**3. Agrega las variables al `.env`:**

```bash
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=lsv2_pt_xxxx
LANGCHAIN_PROJECT=tenmas-playbooks   # nombre del proyecto en LangSmith
```

**No hay que cambiar nada en el c√≥digo** ‚Äî LangChain detecta estas variables autom√°ticamente y env√≠a las trazas a LangSmith en cada ejecuci√≥n.

### Ejecutar el script con tracing activo

```bash
npx tsx scripts/ai/pr-reviewer.ts
```

El script en este repo est√° en [scripts/ai/pr-reviewer.ts](../../scripts/ai/pr-reviewer.ts):

```typescript
import "dotenv/config"; // carga .env autom√°ticamente, incluidas las vars de LangSmith
import { ChatAnthropic } from "@langchain/anthropic";
import { ChatPromptTemplate } from "@langchain/core/prompts";
import { StringOutputParser } from "@langchain/core/output_parsers";

const llm = new ChatAnthropic({
  model: "claude-haiku-4-5-20251001",
  temperature: 0,
  apiKey: process.env.ANTHROPIC_API_KEY,
});

const prompt = ChatPromptTemplate.fromMessages([
  ["system", `Eres un code reviewer t√©cnico. Analiza el diff de PR y responde en espa√±ol con:
1. Resumen de cambios (2-3 l√≠neas)
2. Riesgos detectados (si los hay)
3. Sugerencia de mejora m√°s importante (solo una)

S√© directo y conciso.`],
  ["human", "Diff del PR:\n\n{diff}"],
]);

const chain = prompt.pipe(llm).pipe(new StringOutputParser());

async function reviewPR(diff: string): Promise<string> {
  return chain.invoke({ diff });
}
```

### Salida esperada en consola

```
Analizando diff con LangChain + Claude...

## Resumen
Se a√±ade l√≥gica de autenticaci√≥n que consulta usuarios en BD y genera token.
Sin embargo, contiene una vulnerabilidad cr√≠tica de seguridad.

## Riesgos detectados
üî¥ SQL Injection: La consulta concatena directamente `email` sin escapar.

## Sugerencia de mejora
Usa prepared statements:
const user = await db.query('SELECT * FROM users WHERE email = ?', [email]);

‚úÖ LangChain + Anthropic funcionando correctamente
```

### Qu√© ver en el dashboard de LangSmith

Despu√©s de ejecutar el script, ve a [smith.langchain.com](https://smith.langchain.com) ‚Üí proyecto **tenmas-playbooks**:

- **Runs** ‚Äî cada ejecuci√≥n con el prompt completo y la respuesta
- **Latency** ‚Äî cu√°nto tard√≥ la llamada al LLM
- **Tokens** ‚Äî tokens de entrada y salida (√∫til para estimar costos)
- **Trace** ‚Äî el pipeline completo paso a paso: `ChatPromptTemplate ‚Üí ChatAnthropic ‚Üí StringOutputParser`

### Troubleshooting

**Las trazas no aparecen en LangSmith:**

```bash
# Verifica que las variables est√°n cargadas
node -e "require('dotenv/config'); console.log(process.env.LANGCHAIN_TRACING_V2, process.env.LANGCHAIN_API_KEY?.slice(0,10))"
```

Si `LANGCHAIN_TRACING_V2` no es `"true"` (string, no booleano), el tracing no se activa.

**Error: `LangSmithAuthError`:**

La `LANGCHAIN_API_KEY` est√° mal copiada. Reg√©nera la key en smith.langchain.com ‚Üí Settings ‚Üí API Keys.

---

## Parte 3: Validaci√≥n del stack completo

**Tiempo estimado:** 1.5 horas

Este checklist verifica que los D√≠as 1‚Äì4 funcionan en conjunto. No es opcional ‚Äî es el entregable del d√≠a.

### Verificaci√≥n D√≠a 1: GitHub Copilot

```
1. Abre VS Code o Cursor en cualquier archivo del proyecto
2. Escribe un comentario: "// funci√≥n que valida un email"
3. Espera 2-3 segundos
```

‚úÖ Copilot est√° funcionando si aparece una sugerencia en gris que puedes aceptar con Tab.

‚ùå Si no aparece: verifica que el plugin est√° activo y que est√°s autenticado con la cuenta que tiene licencia Business.

### Verificaci√≥n D√≠a 2: GitHub Security

```
1. Ve a github.com/Tenmas-tech-AI/[tu-repo] ‚Üí pesta√±a Security
2. Verifica que "Dependabot alerts" muestra el estado (aunque sea 0 alertas)
3. Ve a Settings ‚Üí Code security ‚Üí confirma que Secret scanning est√° activo
```

‚úÖ Security est√° funcionando si la pesta√±a Security es visible y Dependabot est√° habilitado.

### Verificaci√≥n D√≠a 2: PR-Agent

```
1. Abre cualquier PR en el repo
2. Escribe en un comentario: /review
3. Espera ~1 minuto
```

‚úÖ PR-Agent est√° funcionando si `github-actions` responde con el **PR Reviewer Guide**.

### Verificaci√≥n D√≠a 3: n8n

```bash
# Levanta n8n si no est√° corriendo
docker compose -f infra/n8n/docker-compose.yml up -d

# Verifica que responde
curl -s -o /dev/null -w "%{http_code}" http://localhost:5678
# Debe retornar: 200
```

```
1. Abre http://localhost:5678
2. Abre cualquier workflow creado ‚Üí click "Test workflow"
3. Verifica que el nodo final muestra output verde
```

‚úÖ n8n est√° funcionando si el workflow ejecuta sin errores.

### Verificaci√≥n D√≠a 3: Playwright

```bash
# Corre los tests E2E
npx playwright test --reporter=line
```

```
# Salida esperada:
7 passed (X.Xs)
```

‚úÖ Playwright est√° funcionando si todos los tests pasan.

‚ùå Si fallan: verifica que la app est√° corriendo en el puerto configurado en `playwright.config.ts`.

### Verificaci√≥n D√≠a 4: LangChain + LangSmith

```bash
# Ejecuta el script del repo
npx tsx scripts/ai/pr-reviewer.ts
```

‚úÖ LangChain est√° funcionando si el agent retorna el an√°lisis del diff de prueba en menos de 30 segundos.

‚úÖ LangSmith est√° funcionando si la traza aparece en [smith.langchain.com](https://smith.langchain.com) ‚Üí proyecto configurado en `LANGCHAIN_PROJECT`.

### Verificaci√≥n de integraci√≥n: n8n ‚Üí LangChain

Este es el test de integraci√≥n m√°s importante. Verifica que n8n puede llamar al agent de LangChain via HTTP.

**1. Exp√≥n el agent como endpoint HTTP:**

```typescript
// src/ai/server.ts
import express from "express";
import { reviewPR } from "./pr-reviewer";
import "dotenv/config";

const app = express();
app.use(express.json());

app.post("/review", async (req, res) => {
  try {
    const { diff } = req.body;
    if (!diff) return res.status(400).json({ error: "diff is required" });
    const review = await reviewPR(diff);
    res.json({ review });
  } catch (err) {
    res.status(500).json({ error: String(err) });
  }
});

app.listen(3001, () => console.log("AI server running on :3001"));
```

```bash
npm install express @types/express
npx tsx src/ai/server.ts
```

**2. Prueba el endpoint:**

```bash
curl -X POST http://localhost:3001/review \
  -H "Content-Type: application/json" \
  -d '{"diff": "+ const x = eval(userInput)"}'
```

**3. En n8n, agrega un nodo HTTP Request:**
- Method: `POST`
- URL: `http://host.docker.internal:3001/review`
- Body: `{ "diff": "{{ $json.body.pull_request.diff_url }}" }`

‚úÖ La integraci√≥n funciona si n8n recibe la respuesta del agent y la puede usar en el siguiente nodo.

---

## Checklist del D√≠a 4 ‚Äî Stack completo D√≠as 1‚Äì4


Al terminar, marca cada item. Si alguno falla, no avances al D√≠a 5.

**D√≠a 1 ‚Äî GitHub Copilot:**
- [ ] Copilot genera sugerencias de c√≥digo en el IDE
- [ ] La cuenta Business est√° activa (no individual)

**D√≠a 2 ‚Äî GitHub Security:**
- [ ] Dependabot alerts activado en los repos de Tenm√°s
- [ ] Secret scanning activado
- [ ] PR-Agent comenta autom√°ticamente en PRs con `/review`

**D√≠a 3 ‚Äî n8n:**
- [ ] n8n corre en `http://localhost:5678`
- [ ] Al menos 1 workflow ejecuta sin errores
- [ ] Webhook de GitHub configurado

**D√≠a 3 ‚Äî Playwright:**
- [ ] `npx playwright test` retorna todos los tests en verde
- [ ] El GitHub Action de Playwright pasa en el PR

**D√≠a 4 ‚Äî LangChain:**
- [ ] `ANTHROPIC_API_KEY` o `OPENAI_API_KEY` cargada correctamente
- [ ] El agent de PR Reviewer ejecuta y retorna respuesta coherente (`npx tsx scripts/ai/pr-reviewer.ts`)
- [ ] El endpoint HTTP del agent responde en `localhost:3001`

**D√≠a 4 ‚Äî LangSmith:**
- [ ] Cuenta creada en [smith.langchain.com](https://smith.langchain.com)
- [ ] `LANGCHAIN_TRACING_V2=true` y `LANGCHAIN_API_KEY` en el `.env`
- [ ] Las trazas aparecen en el dashboard despu√©s de ejecutar el script

**Integraci√≥n:**
- [ ] n8n puede llamar al agent de LangChain via HTTP Request
- [ ] LangSmith registra las trazas de cada ejecuci√≥n del agent
- [ ] No hay errores de autenticaci√≥n entre servicios

---

## Recursos

- [LangChain JS Docs](https://js.langchain.com/docs/)
- [LangChain Python Docs](https://python.langchain.com/docs/)
- [@langchain/anthropic](https://www.npmjs.com/package/@langchain/anthropic)
- [LangChain ‚Äî Expression Language (LCEL)](https://js.langchain.com/docs/concepts/lcel)
- [LangSmith](https://smith.langchain.com) ‚Äî dashboard de observabilidad
- [LangSmith Docs](https://docs.smith.langchain.com/)
- [PromptLayer + LangChain](https://docs.promptlayer.com/languages/python#langchain)

‚û°Ô∏è **Siguiente:** D√≠a 5 ‚Äî Grafana + M√©tricas baseline (pr√≥ximamente)
